{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook explores the performance of the ARGBT2 Mega model, a variant of the ARGBT2 model from Hugging Face, when fine-tuned on the texts of Sheikh Al-Islam Ibn Taymiyyah, may Allah have mercy on him. The primary goal of this experiment is to evaluate how well the ARGBT2 Mega model can adapt and generate text in the style of Sheikh Al-Islam.\n",
    "\n",
    "In this notebook, we employ several advanced configurations to optimize the training process. The model is fine-tuned using the LoRa (Low-Rank Adaptation) configuration, which aims to enhance the model's efficiency and performance by adapting only a subset of the model's parameters. Additionally, we have quantized the model to use 4-bit data type (NF4), which reduces the model's size and computational requirements while maintaining its effectiveness.\n",
    "\n",
    "The notebook is intended to provide a preliminary assessment of the ARGBT2 Mega model's capabilities when working with classical Arabic texts. By fine-tuning the model on these texts, we aim to gain insights into its potential for generating content that aligns with the style and substance of Sheikh Al-Islam Ibn Taymiyyah's writings.\n",
    "\n",
    "This experiment is part of an ongoing effort to understand and refine the model's performance, and the results will help inform future improvements and applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqPrfWudu3fR",
    "outputId": "67bdc7be-0622-4d70-fbab-7589c016f06e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.33.0)\n",
      "Requirement already satisfied: BitsAndBytes in /usr/local/lib/python3.10/dist-packages (0.43.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.0+cu121)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.5)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
      "Requirement already satisfied: arabert in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.0+cu121)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.33.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.4)\n",
      "Requirement already satisfied: PyArabic in /usr/local/lib/python3.10/dist-packages (from arabert) (0.6.15)\n",
      "Requirement already satisfied: farasapy in /usr/local/lib/python3.10/dist-packages (from arabert) (0.0.14)\n",
      "Requirement already satisfied: emoji==1.4.2 in /usr/local/lib/python3.10/dist-packages (from arabert) (1.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from PyArabic->arabert) (1.16.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U transformers accelerate BitsAndBytes\n",
    "! pip install datasets huggingface_hub peft arabert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415,
     "referenced_widgets": [
      "5dd6cd338c004d349a7ca12621ac845b",
      "2e8062385c5644fc9e68da9eec64236f",
      "328613d380ff4b2fb784fd3c52cb4b9d",
      "a08266752c104fe88c9a51aee2dd0f7e",
      "96e007b463894103a2b392edd15e9152",
      "3942ef77622546d98798bde3c9029367",
      "ce4cbe0e35b446e3adafa39fb9165902",
      "edf043d4dc184c058135f9d5282b09f4",
      "78acfd5f456e417da7d45c7c216437a8",
      "722f54204229436da43aedac46242610",
      "0eac0f1c9e244728b1822283bed7ffc3",
      "c7b6267389d64fa58e91546681cd2426",
      "5a38e1e245d3409ab2d06b976c0fc954",
      "1f214f2c799f4952a504f60c50dde628",
      "5fa1feb5b23f4abea9755ae890af97d2",
      "fc31b9ea324a4833aad509f1410f333f",
      "91c1e93743ad454eb03687b60b1bd14e"
     ]
    },
    "id": "tGBT1U2okOhI",
    "outputId": "973a0cda-5f49-43cf-b835-cd8fdc093b4a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd6cd338c004d349a7ca12621ac845b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPov4jUOvGn1"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "from datasets import load_dataset\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Agld__Em5wmb",
    "outputId": "15c85063-9d3a-41a7-f105-0f1b9f6de49d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['bnb_use_double_quan']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type='nf4',\n",
    "                                bnb_4bit_compute_dtype=torch.float16, bnb_use_double_quan=True)\n",
    "\n",
    "check_point = 'aubmindlab/aragpt2-mega'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(check_point, trust_remote_code=True, quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(check_point, trust_remote_code=True)\n",
    "ara_preprocess = ArabertPreprocessor(check_point)\n",
    "\n",
    "raw_dataset = load_dataset('ahmadAlrabghi/Ibn-Taymiyyahs-works-shamilah')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzFmBqvOf9p9"
   },
   "source": [
    "## Fixing The Tokenizer:\n",
    "\n",
    "\n",
    "Issue:\n",
    "\n",
    "The tokenizer dont have a pad token, and the pad token ID = eos token ID\n",
    "\n",
    "and these two things could cause a strange behavoure when fine - tuning\n",
    "\n",
    "So we need to set a paddig token manullay + set the padding token to be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ldf1wN92f9UH",
    "outputId": "0c429784-5251-4aa6-f7a7-51faa062d91f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer len befour padding token: 64000\n",
      "len after adding the new token: 64001\n"
     ]
    }
   ],
   "source": [
    "print(f'tokenizer len befour padding token: {len(tokenizer)}')\n",
    "tokenizer.add_special_tokens({'pad_token':'[PAD]'}) # adding the padding token\n",
    "print(f'len after adding the new token: {len(tokenizer)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zidn_AeAvezJ"
   },
   "outputs": [],
   "source": [
    "# changing the toekenizer len in the model config to make sure it has been modeified and got the padding token ..\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id # changin the pad token id in the model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfwFh0S8wDES",
    "outputId": "8a6914f0-6a9a-434e-f9a3-952a0f1c0203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding token ID in the tokenizer: 64000\n",
      "padding token ID in the model config 64000\n",
      "the padding token from the tokenizer: [PAD]\n",
      "eos token ID in the model: 0, eos token ID in the tokenizer 0\n"
     ]
    }
   ],
   "source": [
    "# Verfy the changes:\n",
    "print(f'padding token ID in the tokenizer: {tokenizer.pad_token_id}')\n",
    "print(f'padding token ID in the model config {model.config.pad_token_id}')\n",
    "print(f'the padding token from the tokenizer: {tokenizer.pad_token}')\n",
    "print(f'eos token ID in the model: {model.config.eos_token_id}, eos token ID in the tokenizer {tokenizer.eos_token_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XeinyJnjwGCr"
   },
   "outputs": [],
   "source": [
    "# setting the padding side to be left cus we are dealing with arabic language :)\n",
    "# tokenizer.padding_side\n",
    "\n",
    "# when I did that I faced some problems when training\n",
    "# the defualt value here is 'right' so i wil stick with it .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qr9jzt2UzVsw"
   },
   "source": [
    "Now we have our model and tokenizer ready to work !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ItZuuk6zSW3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRUYdQyJ5xqx"
   },
   "outputs": [],
   "source": [
    "def tokenizer_function(examples):\n",
    "  cleaned_text = [ara_preprocess.preprocess(text) for text in examples['text']]\n",
    "  tokenized_data  = tokenizer(cleaned_text, padding=True, max_length=1024, truncation=True)\n",
    "  return tokenized_data\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "train_dataset = raw_dataset['train'].map(tokenizer_function, batched=True)\n",
    "eval_dataset = raw_dataset['test'].map(tokenizer_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0v2fg9Mlry3",
    "outputId": "be9244e7-c82e-4b5d-9c75-00872d2684f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 244955\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiNUi96Xjy-a",
    "outputId": "b3f99ba2-c024-4cc0-8cb6-eb9c0fc9264f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 48991\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using just 20% of the data that we have..\n",
    "# becuase train the model on all of that text requirse a lots of computation resourses + I am still testing the model and the data\n",
    "sub_train = train_dataset.select(range(int(train_dataset.num_rows * 0.20)))\n",
    "sub_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwOZtYB4B4XR",
    "outputId": "6cc97b87-8e8e-4a04-a8aa-5d609eb0e83b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "transformer\n",
      "transformer.wte\n",
      "transformer.wpe\n",
      "transformer.emb_norm\n",
      "transformer.drop\n",
      "transformer.h\n",
      "transformer.h.0\n",
      "transformer.h.0.ln_1\n",
      "transformer.h.0.attn\n",
      "transformer.h.0.attn.c_attn\n",
      "transformer.h.0.attn.c_proj\n",
      "transformer.h.0.attn.attn_dropout\n",
      "transformer.h.0.attn.resid_dropout\n",
      "transformer.h.0.ln_2\n",
      "transformer.h.0.mlp\n",
      "transformer.h.0.mlp.c_fc\n",
      "transformer.h.0.mlp.c_proj\n",
      "transformer.h.0.mlp.act\n",
      "transformer.h.0.mlp.dropout\n",
      "transformer.h.1\n",
      "transformer.h.1.ln_1\n",
      "transformer.h.1.attn\n",
      "transformer.h.1.attn.c_attn\n",
      "transformer.h.1.attn.c_proj\n",
      "transformer.h.1.attn.attn_dropout\n",
      "transformer.h.1.attn.resid_dropout\n",
      "transformer.h.1.ln_2\n",
      "transformer.h.1.mlp\n",
      "transformer.h.1.mlp.c_fc\n",
      "transformer.h.1.mlp.c_proj\n",
      "transformer.h.1.mlp.act\n",
      "transformer.h.1.mlp.dropout\n",
      "transformer.h.2\n",
      "transformer.h.2.ln_1\n",
      "transformer.h.2.attn\n",
      "transformer.h.2.attn.c_attn\n",
      "transformer.h.2.attn.c_proj\n",
      "transformer.h.2.attn.attn_dropout\n",
      "transformer.h.2.attn.resid_dropout\n",
      "transformer.h.2.ln_2\n",
      "transformer.h.2.mlp\n",
      "transformer.h.2.mlp.c_fc\n",
      "transformer.h.2.mlp.c_proj\n",
      "transformer.h.2.mlp.act\n",
      "transformer.h.2.mlp.dropout\n",
      "transformer.h.3\n",
      "transformer.h.3.ln_1\n",
      "transformer.h.3.attn\n",
      "transformer.h.3.attn.c_attn\n",
      "transformer.h.3.attn.c_proj\n",
      "transformer.h.3.attn.attn_dropout\n",
      "transformer.h.3.attn.resid_dropout\n",
      "transformer.h.3.ln_2\n",
      "transformer.h.3.mlp\n",
      "transformer.h.3.mlp.c_fc\n",
      "transformer.h.3.mlp.c_proj\n",
      "transformer.h.3.mlp.act\n",
      "transformer.h.3.mlp.dropout\n",
      "transformer.h.4\n",
      "transformer.h.4.ln_1\n",
      "transformer.h.4.attn\n",
      "transformer.h.4.attn.c_attn\n",
      "transformer.h.4.attn.c_proj\n",
      "transformer.h.4.attn.attn_dropout\n",
      "transformer.h.4.attn.resid_dropout\n",
      "transformer.h.4.ln_2\n",
      "transformer.h.4.mlp\n",
      "transformer.h.4.mlp.c_fc\n",
      "transformer.h.4.mlp.c_proj\n",
      "transformer.h.4.mlp.act\n",
      "transformer.h.4.mlp.dropout\n",
      "transformer.h.5\n",
      "transformer.h.5.ln_1\n",
      "transformer.h.5.attn\n",
      "transformer.h.5.attn.c_attn\n",
      "transformer.h.5.attn.c_proj\n",
      "transformer.h.5.attn.attn_dropout\n",
      "transformer.h.5.attn.resid_dropout\n",
      "transformer.h.5.ln_2\n",
      "transformer.h.5.mlp\n",
      "transformer.h.5.mlp.c_fc\n",
      "transformer.h.5.mlp.c_proj\n",
      "transformer.h.5.mlp.act\n",
      "transformer.h.5.mlp.dropout\n",
      "transformer.h.6\n",
      "transformer.h.6.ln_1\n",
      "transformer.h.6.attn\n",
      "transformer.h.6.attn.c_attn\n",
      "transformer.h.6.attn.c_proj\n",
      "transformer.h.6.attn.attn_dropout\n",
      "transformer.h.6.attn.resid_dropout\n",
      "transformer.h.6.ln_2\n",
      "transformer.h.6.mlp\n",
      "transformer.h.6.mlp.c_fc\n",
      "transformer.h.6.mlp.c_proj\n",
      "transformer.h.6.mlp.act\n",
      "transformer.h.6.mlp.dropout\n",
      "transformer.h.7\n",
      "transformer.h.7.ln_1\n",
      "transformer.h.7.attn\n",
      "transformer.h.7.attn.c_attn\n",
      "transformer.h.7.attn.c_proj\n",
      "transformer.h.7.attn.attn_dropout\n",
      "transformer.h.7.attn.resid_dropout\n",
      "transformer.h.7.ln_2\n",
      "transformer.h.7.mlp\n",
      "transformer.h.7.mlp.c_fc\n",
      "transformer.h.7.mlp.c_proj\n",
      "transformer.h.7.mlp.act\n",
      "transformer.h.7.mlp.dropout\n",
      "transformer.h.8\n",
      "transformer.h.8.ln_1\n",
      "transformer.h.8.attn\n",
      "transformer.h.8.attn.c_attn\n",
      "transformer.h.8.attn.c_proj\n",
      "transformer.h.8.attn.attn_dropout\n",
      "transformer.h.8.attn.resid_dropout\n",
      "transformer.h.8.ln_2\n",
      "transformer.h.8.mlp\n",
      "transformer.h.8.mlp.c_fc\n",
      "transformer.h.8.mlp.c_proj\n",
      "transformer.h.8.mlp.act\n",
      "transformer.h.8.mlp.dropout\n",
      "transformer.h.9\n",
      "transformer.h.9.ln_1\n",
      "transformer.h.9.attn\n",
      "transformer.h.9.attn.c_attn\n",
      "transformer.h.9.attn.c_proj\n",
      "transformer.h.9.attn.attn_dropout\n",
      "transformer.h.9.attn.resid_dropout\n",
      "transformer.h.9.ln_2\n",
      "transformer.h.9.mlp\n",
      "transformer.h.9.mlp.c_fc\n",
      "transformer.h.9.mlp.c_proj\n",
      "transformer.h.9.mlp.act\n",
      "transformer.h.9.mlp.dropout\n",
      "transformer.h.10\n",
      "transformer.h.10.ln_1\n",
      "transformer.h.10.attn\n",
      "transformer.h.10.attn.c_attn\n",
      "transformer.h.10.attn.c_proj\n",
      "transformer.h.10.attn.attn_dropout\n",
      "transformer.h.10.attn.resid_dropout\n",
      "transformer.h.10.ln_2\n",
      "transformer.h.10.mlp\n",
      "transformer.h.10.mlp.c_fc\n",
      "transformer.h.10.mlp.c_proj\n",
      "transformer.h.10.mlp.act\n",
      "transformer.h.10.mlp.dropout\n",
      "transformer.h.11\n",
      "transformer.h.11.ln_1\n",
      "transformer.h.11.attn\n",
      "transformer.h.11.attn.c_attn\n",
      "transformer.h.11.attn.c_proj\n",
      "transformer.h.11.attn.attn_dropout\n",
      "transformer.h.11.attn.resid_dropout\n",
      "transformer.h.11.ln_2\n",
      "transformer.h.11.mlp\n",
      "transformer.h.11.mlp.c_fc\n",
      "transformer.h.11.mlp.c_proj\n",
      "transformer.h.11.mlp.act\n",
      "transformer.h.11.mlp.dropout\n",
      "transformer.h.12\n",
      "transformer.h.12.ln_1\n",
      "transformer.h.12.attn\n",
      "transformer.h.12.attn.c_attn\n",
      "transformer.h.12.attn.c_proj\n",
      "transformer.h.12.attn.attn_dropout\n",
      "transformer.h.12.attn.resid_dropout\n",
      "transformer.h.12.ln_2\n",
      "transformer.h.12.mlp\n",
      "transformer.h.12.mlp.c_fc\n",
      "transformer.h.12.mlp.c_proj\n",
      "transformer.h.12.mlp.act\n",
      "transformer.h.12.mlp.dropout\n",
      "transformer.h.13\n",
      "transformer.h.13.ln_1\n",
      "transformer.h.13.attn\n",
      "transformer.h.13.attn.c_attn\n",
      "transformer.h.13.attn.c_proj\n",
      "transformer.h.13.attn.attn_dropout\n",
      "transformer.h.13.attn.resid_dropout\n",
      "transformer.h.13.ln_2\n",
      "transformer.h.13.mlp\n",
      "transformer.h.13.mlp.c_fc\n",
      "transformer.h.13.mlp.c_proj\n",
      "transformer.h.13.mlp.act\n",
      "transformer.h.13.mlp.dropout\n",
      "transformer.h.14\n",
      "transformer.h.14.ln_1\n",
      "transformer.h.14.attn\n",
      "transformer.h.14.attn.c_attn\n",
      "transformer.h.14.attn.c_proj\n",
      "transformer.h.14.attn.attn_dropout\n",
      "transformer.h.14.attn.resid_dropout\n",
      "transformer.h.14.ln_2\n",
      "transformer.h.14.mlp\n",
      "transformer.h.14.mlp.c_fc\n",
      "transformer.h.14.mlp.c_proj\n",
      "transformer.h.14.mlp.act\n",
      "transformer.h.14.mlp.dropout\n",
      "transformer.h.15\n",
      "transformer.h.15.ln_1\n",
      "transformer.h.15.attn\n",
      "transformer.h.15.attn.c_attn\n",
      "transformer.h.15.attn.c_proj\n",
      "transformer.h.15.attn.attn_dropout\n",
      "transformer.h.15.attn.resid_dropout\n",
      "transformer.h.15.ln_2\n",
      "transformer.h.15.mlp\n",
      "transformer.h.15.mlp.c_fc\n",
      "transformer.h.15.mlp.c_proj\n",
      "transformer.h.15.mlp.act\n",
      "transformer.h.15.mlp.dropout\n",
      "transformer.h.16\n",
      "transformer.h.16.ln_1\n",
      "transformer.h.16.attn\n",
      "transformer.h.16.attn.c_attn\n",
      "transformer.h.16.attn.c_proj\n",
      "transformer.h.16.attn.attn_dropout\n",
      "transformer.h.16.attn.resid_dropout\n",
      "transformer.h.16.ln_2\n",
      "transformer.h.16.mlp\n",
      "transformer.h.16.mlp.c_fc\n",
      "transformer.h.16.mlp.c_proj\n",
      "transformer.h.16.mlp.act\n",
      "transformer.h.16.mlp.dropout\n",
      "transformer.h.17\n",
      "transformer.h.17.ln_1\n",
      "transformer.h.17.attn\n",
      "transformer.h.17.attn.c_attn\n",
      "transformer.h.17.attn.c_proj\n",
      "transformer.h.17.attn.attn_dropout\n",
      "transformer.h.17.attn.resid_dropout\n",
      "transformer.h.17.ln_2\n",
      "transformer.h.17.mlp\n",
      "transformer.h.17.mlp.c_fc\n",
      "transformer.h.17.mlp.c_proj\n",
      "transformer.h.17.mlp.act\n",
      "transformer.h.17.mlp.dropout\n",
      "transformer.h.18\n",
      "transformer.h.18.ln_1\n",
      "transformer.h.18.attn\n",
      "transformer.h.18.attn.c_attn\n",
      "transformer.h.18.attn.c_proj\n",
      "transformer.h.18.attn.attn_dropout\n",
      "transformer.h.18.attn.resid_dropout\n",
      "transformer.h.18.ln_2\n",
      "transformer.h.18.mlp\n",
      "transformer.h.18.mlp.c_fc\n",
      "transformer.h.18.mlp.c_proj\n",
      "transformer.h.18.mlp.act\n",
      "transformer.h.18.mlp.dropout\n",
      "transformer.h.19\n",
      "transformer.h.19.ln_1\n",
      "transformer.h.19.attn\n",
      "transformer.h.19.attn.c_attn\n",
      "transformer.h.19.attn.c_proj\n",
      "transformer.h.19.attn.attn_dropout\n",
      "transformer.h.19.attn.resid_dropout\n",
      "transformer.h.19.ln_2\n",
      "transformer.h.19.mlp\n",
      "transformer.h.19.mlp.c_fc\n",
      "transformer.h.19.mlp.c_proj\n",
      "transformer.h.19.mlp.act\n",
      "transformer.h.19.mlp.dropout\n",
      "transformer.h.20\n",
      "transformer.h.20.ln_1\n",
      "transformer.h.20.attn\n",
      "transformer.h.20.attn.c_attn\n",
      "transformer.h.20.attn.c_proj\n",
      "transformer.h.20.attn.attn_dropout\n",
      "transformer.h.20.attn.resid_dropout\n",
      "transformer.h.20.ln_2\n",
      "transformer.h.20.mlp\n",
      "transformer.h.20.mlp.c_fc\n",
      "transformer.h.20.mlp.c_proj\n",
      "transformer.h.20.mlp.act\n",
      "transformer.h.20.mlp.dropout\n",
      "transformer.h.21\n",
      "transformer.h.21.ln_1\n",
      "transformer.h.21.attn\n",
      "transformer.h.21.attn.c_attn\n",
      "transformer.h.21.attn.c_proj\n",
      "transformer.h.21.attn.attn_dropout\n",
      "transformer.h.21.attn.resid_dropout\n",
      "transformer.h.21.ln_2\n",
      "transformer.h.21.mlp\n",
      "transformer.h.21.mlp.c_fc\n",
      "transformer.h.21.mlp.c_proj\n",
      "transformer.h.21.mlp.act\n",
      "transformer.h.21.mlp.dropout\n",
      "transformer.h.22\n",
      "transformer.h.22.ln_1\n",
      "transformer.h.22.attn\n",
      "transformer.h.22.attn.c_attn\n",
      "transformer.h.22.attn.c_proj\n",
      "transformer.h.22.attn.attn_dropout\n",
      "transformer.h.22.attn.resid_dropout\n",
      "transformer.h.22.ln_2\n",
      "transformer.h.22.mlp\n",
      "transformer.h.22.mlp.c_fc\n",
      "transformer.h.22.mlp.c_proj\n",
      "transformer.h.22.mlp.act\n",
      "transformer.h.22.mlp.dropout\n",
      "transformer.h.23\n",
      "transformer.h.23.ln_1\n",
      "transformer.h.23.attn\n",
      "transformer.h.23.attn.c_attn\n",
      "transformer.h.23.attn.c_proj\n",
      "transformer.h.23.attn.attn_dropout\n",
      "transformer.h.23.attn.resid_dropout\n",
      "transformer.h.23.ln_2\n",
      "transformer.h.23.mlp\n",
      "transformer.h.23.mlp.c_fc\n",
      "transformer.h.23.mlp.c_proj\n",
      "transformer.h.23.mlp.act\n",
      "transformer.h.23.mlp.dropout\n",
      "transformer.h.24\n",
      "transformer.h.24.ln_1\n",
      "transformer.h.24.attn\n",
      "transformer.h.24.attn.c_attn\n",
      "transformer.h.24.attn.c_proj\n",
      "transformer.h.24.attn.attn_dropout\n",
      "transformer.h.24.attn.resid_dropout\n",
      "transformer.h.24.ln_2\n",
      "transformer.h.24.mlp\n",
      "transformer.h.24.mlp.c_fc\n",
      "transformer.h.24.mlp.c_proj\n",
      "transformer.h.24.mlp.act\n",
      "transformer.h.24.mlp.dropout\n",
      "transformer.h.25\n",
      "transformer.h.25.ln_1\n",
      "transformer.h.25.attn\n",
      "transformer.h.25.attn.c_attn\n",
      "transformer.h.25.attn.c_proj\n",
      "transformer.h.25.attn.attn_dropout\n",
      "transformer.h.25.attn.resid_dropout\n",
      "transformer.h.25.ln_2\n",
      "transformer.h.25.mlp\n",
      "transformer.h.25.mlp.c_fc\n",
      "transformer.h.25.mlp.c_proj\n",
      "transformer.h.25.mlp.act\n",
      "transformer.h.25.mlp.dropout\n",
      "transformer.h.26\n",
      "transformer.h.26.ln_1\n",
      "transformer.h.26.attn\n",
      "transformer.h.26.attn.c_attn\n",
      "transformer.h.26.attn.c_proj\n",
      "transformer.h.26.attn.attn_dropout\n",
      "transformer.h.26.attn.resid_dropout\n",
      "transformer.h.26.ln_2\n",
      "transformer.h.26.mlp\n",
      "transformer.h.26.mlp.c_fc\n",
      "transformer.h.26.mlp.c_proj\n",
      "transformer.h.26.mlp.act\n",
      "transformer.h.26.mlp.dropout\n",
      "transformer.h.27\n",
      "transformer.h.27.ln_1\n",
      "transformer.h.27.attn\n",
      "transformer.h.27.attn.c_attn\n",
      "transformer.h.27.attn.c_proj\n",
      "transformer.h.27.attn.attn_dropout\n",
      "transformer.h.27.attn.resid_dropout\n",
      "transformer.h.27.ln_2\n",
      "transformer.h.27.mlp\n",
      "transformer.h.27.mlp.c_fc\n",
      "transformer.h.27.mlp.c_proj\n",
      "transformer.h.27.mlp.act\n",
      "transformer.h.27.mlp.dropout\n",
      "transformer.h.28\n",
      "transformer.h.28.ln_1\n",
      "transformer.h.28.attn\n",
      "transformer.h.28.attn.c_attn\n",
      "transformer.h.28.attn.c_proj\n",
      "transformer.h.28.attn.attn_dropout\n",
      "transformer.h.28.attn.resid_dropout\n",
      "transformer.h.28.ln_2\n",
      "transformer.h.28.mlp\n",
      "transformer.h.28.mlp.c_fc\n",
      "transformer.h.28.mlp.c_proj\n",
      "transformer.h.28.mlp.act\n",
      "transformer.h.28.mlp.dropout\n",
      "transformer.h.29\n",
      "transformer.h.29.ln_1\n",
      "transformer.h.29.attn\n",
      "transformer.h.29.attn.c_attn\n",
      "transformer.h.29.attn.c_proj\n",
      "transformer.h.29.attn.attn_dropout\n",
      "transformer.h.29.attn.resid_dropout\n",
      "transformer.h.29.ln_2\n",
      "transformer.h.29.mlp\n",
      "transformer.h.29.mlp.c_fc\n",
      "transformer.h.29.mlp.c_proj\n",
      "transformer.h.29.mlp.act\n",
      "transformer.h.29.mlp.dropout\n",
      "transformer.h.30\n",
      "transformer.h.30.ln_1\n",
      "transformer.h.30.attn\n",
      "transformer.h.30.attn.c_attn\n",
      "transformer.h.30.attn.c_proj\n",
      "transformer.h.30.attn.attn_dropout\n",
      "transformer.h.30.attn.resid_dropout\n",
      "transformer.h.30.ln_2\n",
      "transformer.h.30.mlp\n",
      "transformer.h.30.mlp.c_fc\n",
      "transformer.h.30.mlp.c_proj\n",
      "transformer.h.30.mlp.act\n",
      "transformer.h.30.mlp.dropout\n",
      "transformer.h.31\n",
      "transformer.h.31.ln_1\n",
      "transformer.h.31.attn\n",
      "transformer.h.31.attn.c_attn\n",
      "transformer.h.31.attn.c_proj\n",
      "transformer.h.31.attn.attn_dropout\n",
      "transformer.h.31.attn.resid_dropout\n",
      "transformer.h.31.ln_2\n",
      "transformer.h.31.mlp\n",
      "transformer.h.31.mlp.c_fc\n",
      "transformer.h.31.mlp.c_proj\n",
      "transformer.h.31.mlp.act\n",
      "transformer.h.31.mlp.dropout\n",
      "transformer.h.32\n",
      "transformer.h.32.ln_1\n",
      "transformer.h.32.attn\n",
      "transformer.h.32.attn.c_attn\n",
      "transformer.h.32.attn.c_proj\n",
      "transformer.h.32.attn.attn_dropout\n",
      "transformer.h.32.attn.resid_dropout\n",
      "transformer.h.32.ln_2\n",
      "transformer.h.32.mlp\n",
      "transformer.h.32.mlp.c_fc\n",
      "transformer.h.32.mlp.c_proj\n",
      "transformer.h.32.mlp.act\n",
      "transformer.h.32.mlp.dropout\n",
      "transformer.h.33\n",
      "transformer.h.33.ln_1\n",
      "transformer.h.33.attn\n",
      "transformer.h.33.attn.c_attn\n",
      "transformer.h.33.attn.c_proj\n",
      "transformer.h.33.attn.attn_dropout\n",
      "transformer.h.33.attn.resid_dropout\n",
      "transformer.h.33.ln_2\n",
      "transformer.h.33.mlp\n",
      "transformer.h.33.mlp.c_fc\n",
      "transformer.h.33.mlp.c_proj\n",
      "transformer.h.33.mlp.act\n",
      "transformer.h.33.mlp.dropout\n",
      "transformer.h.34\n",
      "transformer.h.34.ln_1\n",
      "transformer.h.34.attn\n",
      "transformer.h.34.attn.c_attn\n",
      "transformer.h.34.attn.c_proj\n",
      "transformer.h.34.attn.attn_dropout\n",
      "transformer.h.34.attn.resid_dropout\n",
      "transformer.h.34.ln_2\n",
      "transformer.h.34.mlp\n",
      "transformer.h.34.mlp.c_fc\n",
      "transformer.h.34.mlp.c_proj\n",
      "transformer.h.34.mlp.act\n",
      "transformer.h.34.mlp.dropout\n",
      "transformer.h.35\n",
      "transformer.h.35.ln_1\n",
      "transformer.h.35.attn\n",
      "transformer.h.35.attn.c_attn\n",
      "transformer.h.35.attn.c_proj\n",
      "transformer.h.35.attn.attn_dropout\n",
      "transformer.h.35.attn.resid_dropout\n",
      "transformer.h.35.ln_2\n",
      "transformer.h.35.mlp\n",
      "transformer.h.35.mlp.c_fc\n",
      "transformer.h.35.mlp.c_proj\n",
      "transformer.h.35.mlp.act\n",
      "transformer.h.35.mlp.dropout\n",
      "transformer.h.36\n",
      "transformer.h.36.ln_1\n",
      "transformer.h.36.attn\n",
      "transformer.h.36.attn.c_attn\n",
      "transformer.h.36.attn.c_proj\n",
      "transformer.h.36.attn.attn_dropout\n",
      "transformer.h.36.attn.resid_dropout\n",
      "transformer.h.36.ln_2\n",
      "transformer.h.36.mlp\n",
      "transformer.h.36.mlp.c_fc\n",
      "transformer.h.36.mlp.c_proj\n",
      "transformer.h.36.mlp.act\n",
      "transformer.h.36.mlp.dropout\n",
      "transformer.h.37\n",
      "transformer.h.37.ln_1\n",
      "transformer.h.37.attn\n",
      "transformer.h.37.attn.c_attn\n",
      "transformer.h.37.attn.c_proj\n",
      "transformer.h.37.attn.attn_dropout\n",
      "transformer.h.37.attn.resid_dropout\n",
      "transformer.h.37.ln_2\n",
      "transformer.h.37.mlp\n",
      "transformer.h.37.mlp.c_fc\n",
      "transformer.h.37.mlp.c_proj\n",
      "transformer.h.37.mlp.act\n",
      "transformer.h.37.mlp.dropout\n",
      "transformer.h.38\n",
      "transformer.h.38.ln_1\n",
      "transformer.h.38.attn\n",
      "transformer.h.38.attn.c_attn\n",
      "transformer.h.38.attn.c_proj\n",
      "transformer.h.38.attn.attn_dropout\n",
      "transformer.h.38.attn.resid_dropout\n",
      "transformer.h.38.ln_2\n",
      "transformer.h.38.mlp\n",
      "transformer.h.38.mlp.c_fc\n",
      "transformer.h.38.mlp.c_proj\n",
      "transformer.h.38.mlp.act\n",
      "transformer.h.38.mlp.dropout\n",
      "transformer.h.39\n",
      "transformer.h.39.ln_1\n",
      "transformer.h.39.attn\n",
      "transformer.h.39.attn.c_attn\n",
      "transformer.h.39.attn.c_proj\n",
      "transformer.h.39.attn.attn_dropout\n",
      "transformer.h.39.attn.resid_dropout\n",
      "transformer.h.39.ln_2\n",
      "transformer.h.39.mlp\n",
      "transformer.h.39.mlp.c_fc\n",
      "transformer.h.39.mlp.c_proj\n",
      "transformer.h.39.mlp.act\n",
      "transformer.h.39.mlp.dropout\n",
      "transformer.h.40\n",
      "transformer.h.40.ln_1\n",
      "transformer.h.40.attn\n",
      "transformer.h.40.attn.c_attn\n",
      "transformer.h.40.attn.c_proj\n",
      "transformer.h.40.attn.attn_dropout\n",
      "transformer.h.40.attn.resid_dropout\n",
      "transformer.h.40.ln_2\n",
      "transformer.h.40.mlp\n",
      "transformer.h.40.mlp.c_fc\n",
      "transformer.h.40.mlp.c_proj\n",
      "transformer.h.40.mlp.act\n",
      "transformer.h.40.mlp.dropout\n",
      "transformer.h.41\n",
      "transformer.h.41.ln_1\n",
      "transformer.h.41.attn\n",
      "transformer.h.41.attn.c_attn\n",
      "transformer.h.41.attn.c_proj\n",
      "transformer.h.41.attn.attn_dropout\n",
      "transformer.h.41.attn.resid_dropout\n",
      "transformer.h.41.ln_2\n",
      "transformer.h.41.mlp\n",
      "transformer.h.41.mlp.c_fc\n",
      "transformer.h.41.mlp.c_proj\n",
      "transformer.h.41.mlp.act\n",
      "transformer.h.41.mlp.dropout\n",
      "transformer.h.42\n",
      "transformer.h.42.ln_1\n",
      "transformer.h.42.attn\n",
      "transformer.h.42.attn.c_attn\n",
      "transformer.h.42.attn.c_proj\n",
      "transformer.h.42.attn.attn_dropout\n",
      "transformer.h.42.attn.resid_dropout\n",
      "transformer.h.42.ln_2\n",
      "transformer.h.42.mlp\n",
      "transformer.h.42.mlp.c_fc\n",
      "transformer.h.42.mlp.c_proj\n",
      "transformer.h.42.mlp.act\n",
      "transformer.h.42.mlp.dropout\n",
      "transformer.h.43\n",
      "transformer.h.43.ln_1\n",
      "transformer.h.43.attn\n",
      "transformer.h.43.attn.c_attn\n",
      "transformer.h.43.attn.c_proj\n",
      "transformer.h.43.attn.attn_dropout\n",
      "transformer.h.43.attn.resid_dropout\n",
      "transformer.h.43.ln_2\n",
      "transformer.h.43.mlp\n",
      "transformer.h.43.mlp.c_fc\n",
      "transformer.h.43.mlp.c_proj\n",
      "transformer.h.43.mlp.act\n",
      "transformer.h.43.mlp.dropout\n",
      "transformer.h.44\n",
      "transformer.h.44.ln_1\n",
      "transformer.h.44.attn\n",
      "transformer.h.44.attn.c_attn\n",
      "transformer.h.44.attn.c_proj\n",
      "transformer.h.44.attn.attn_dropout\n",
      "transformer.h.44.attn.resid_dropout\n",
      "transformer.h.44.ln_2\n",
      "transformer.h.44.mlp\n",
      "transformer.h.44.mlp.c_fc\n",
      "transformer.h.44.mlp.c_proj\n",
      "transformer.h.44.mlp.act\n",
      "transformer.h.44.mlp.dropout\n",
      "transformer.h.45\n",
      "transformer.h.45.ln_1\n",
      "transformer.h.45.attn\n",
      "transformer.h.45.attn.c_attn\n",
      "transformer.h.45.attn.c_proj\n",
      "transformer.h.45.attn.attn_dropout\n",
      "transformer.h.45.attn.resid_dropout\n",
      "transformer.h.45.ln_2\n",
      "transformer.h.45.mlp\n",
      "transformer.h.45.mlp.c_fc\n",
      "transformer.h.45.mlp.c_proj\n",
      "transformer.h.45.mlp.act\n",
      "transformer.h.45.mlp.dropout\n",
      "transformer.h.46\n",
      "transformer.h.46.ln_1\n",
      "transformer.h.46.attn\n",
      "transformer.h.46.attn.c_attn\n",
      "transformer.h.46.attn.c_proj\n",
      "transformer.h.46.attn.attn_dropout\n",
      "transformer.h.46.attn.resid_dropout\n",
      "transformer.h.46.ln_2\n",
      "transformer.h.46.mlp\n",
      "transformer.h.46.mlp.c_fc\n",
      "transformer.h.46.mlp.c_proj\n",
      "transformer.h.46.mlp.act\n",
      "transformer.h.46.mlp.dropout\n",
      "transformer.h.47\n",
      "transformer.h.47.ln_1\n",
      "transformer.h.47.attn\n",
      "transformer.h.47.attn.c_attn\n",
      "transformer.h.47.attn.c_proj\n",
      "transformer.h.47.attn.attn_dropout\n",
      "transformer.h.47.attn.resid_dropout\n",
      "transformer.h.47.ln_2\n",
      "transformer.h.47.mlp\n",
      "transformer.h.47.mlp.c_fc\n",
      "transformer.h.47.mlp.c_proj\n",
      "transformer.h.47.mlp.act\n",
      "transformer.h.47.mlp.dropout\n",
      "lm_head\n"
     ]
    }
   ],
   "source": [
    "# getting the model layers name so we can apply lora on the criticle ones\n",
    "for name, module in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6GQZyAhWJbv"
   },
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "lora_config = LoraConfig(r=4, lora_alpha=32, lora_dropout=0.1, bias='none', task_type='CAUSAL_LM',\n",
    "                         # these are the self attetion layers in ara-gpt-2-mega, it may very from a model to another\n",
    "                         target_modules = [\"c_attn\", \"c_proj\"])\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vf7KifAj5x2R"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(learning_rate=2e-6, per_device_train_batch_size=64,\n",
    "                                  num_train_epochs=3, output_dir='outputs',\n",
    "                                  gradient_accumulation_steps=2, warmup_steps=round(500*0.2), # about 30% of the first epoch, the best thing is to keep it at 20%\n",
    "                                  optim='paged_adamw_8bit', per_device_eval_batch_size=4, push_to_hub=True, hub_model_id = 'ahmadAlrabghi/AraGPT2-IbnTaymiyyah' )\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer, data_collator=data_collator,\n",
    "                  args=training_args, train_dataset=sub_train, eval_dataset=eval_dataset)\n",
    "\n",
    "model.config.use_cache = False # just while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "rmYD4rit5x6v",
    "outputId": "e2e12de5-250d-4751-fabc-9100a504b72e"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1120' max='1149' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1120/1149 17:33:18 < 27:19, 0.02 it/s, Epoch 2.92/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.843600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.686100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1149' max='1149' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1149/1149 18:01:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.843600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.686100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ahmadAlrabghi/AraGPT2-IbnTaymiyyah/commit/2c8d27bf37f8bb46f5f2855382f791470729ea90', commit_message='End of training', commit_description='', oid='2c8d27bf37f8bb46f5f2855382f791470729ea90', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2kWUkKx5yB6",
    "outputId": "af75387e-4f37-4ed4-ab12-b3541b52af7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "drive.flush_and_unmount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-Uq8AoGjpym",
    "outputId": "f286c489-d5f0-4b9d-bc51-655ce38d0667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: outputs/ (stored 0%)\n",
      "  adding: outputs/checkpoint-1149/ (stored 0%)\n",
      "  adding: outputs/checkpoint-1149/optimizer.pt (deflated 17%)\n",
      "  adding: outputs/checkpoint-1149/vocab.json (deflated 75%)\n",
      "  adding: outputs/checkpoint-1149/adapter_model.safetensors (deflated 41%)\n",
      "  adding: outputs/checkpoint-1149/training_args.bin (deflated 51%)\n",
      "  adding: outputs/checkpoint-1149/merges.txt (deflated 77%)\n",
      "  adding: outputs/checkpoint-1149/README.md (deflated 66%)\n",
      "  adding: outputs/checkpoint-1149/tokenizer.json (deflated 80%)\n",
      "  adding: outputs/checkpoint-1149/adapter_config.json (deflated 51%)\n",
      "  adding: outputs/checkpoint-1149/tokenizer_config.json (deflated 76%)\n",
      "  adding: outputs/checkpoint-1149/scheduler.pt (deflated 56%)\n",
      "  adding: outputs/checkpoint-1149/rng_state.pth (deflated 25%)\n",
      "  adding: outputs/checkpoint-1149/trainer_state.json (deflated 56%)\n",
      "  adding: outputs/checkpoint-1149/special_tokens_map.json (deflated 48%)\n",
      "  adding: outputs/checkpoint-1149/added_tokens.json (stored 0%)\n",
      "  adding: outputs/vocab.json (deflated 75%)\n",
      "  adding: outputs/adapter_model.safetensors (deflated 41%)\n",
      "  adding: outputs/training_args.bin (deflated 51%)\n",
      "  adding: outputs/runs/ (stored 0%)\n",
      "  adding: outputs/runs/Aug26_21-29-37_269f7f9e9f50/ (stored 0%)\n",
      "  adding: outputs/runs/Aug26_21-29-37_269f7f9e9f50/events.out.tfevents.1724707780.269f7f9e9f50.1840.0 (deflated 62%)\n",
      "  adding: outputs/runs/Aug26_21-39-47_269f7f9e9f50/ (stored 0%)\n",
      "  adding: outputs/runs/Aug26_21-39-47_269f7f9e9f50/events.out.tfevents.1724708389.269f7f9e9f50.6378.0 (deflated 60%)\n",
      "  adding: outputs/runs/Aug26_21-34-47_269f7f9e9f50/ (stored 0%)\n",
      "  adding: outputs/runs/Aug26_21-34-47_269f7f9e9f50/events.out.tfevents.1724708088.269f7f9e9f50.4909.0 (deflated 62%)\n",
      "  adding: outputs/merges.txt (deflated 77%)\n",
      "  adding: outputs/README.md (deflated 47%)\n",
      "  adding: outputs/tokenizer.json (deflated 80%)\n",
      "  adding: outputs/adapter_config.json (deflated 51%)\n",
      "  adding: outputs/tokenizer_config.json (deflated 76%)\n",
      "  adding: outputs/checkpoint-1000/ (stored 0%)\n",
      "  adding: outputs/checkpoint-1000/optimizer.pt (deflated 17%)\n",
      "  adding: outputs/checkpoint-1000/vocab.json (deflated 75%)\n",
      "  adding: outputs/checkpoint-1000/adapter_model.safetensors (deflated 41%)\n",
      "  adding: outputs/checkpoint-1000/training_args.bin (deflated 51%)\n",
      "  adding: outputs/checkpoint-1000/merges.txt (deflated 77%)\n",
      "  adding: outputs/checkpoint-1000/README.md (deflated 66%)\n",
      "  adding: outputs/checkpoint-1000/tokenizer.json (deflated 80%)\n",
      "  adding: outputs/checkpoint-1000/adapter_config.json (deflated 51%)\n",
      "  adding: outputs/checkpoint-1000/tokenizer_config.json (deflated 76%)\n",
      "  adding: outputs/checkpoint-1000/scheduler.pt (deflated 55%)\n",
      "  adding: outputs/checkpoint-1000/rng_state.pth (deflated 25%)\n",
      "  adding: outputs/checkpoint-1000/trainer_state.json (deflated 56%)\n",
      "  adding: outputs/checkpoint-1000/special_tokens_map.json (deflated 48%)\n",
      "  adding: outputs/checkpoint-1000/added_tokens.json (stored 0%)\n",
      "  adding: outputs/special_tokens_map.json (deflated 48%)\n",
      "  adding: outputs/checkpoint-500/ (stored 0%)\n",
      "  adding: outputs/checkpoint-500/optimizer.pt (deflated 17%)\n",
      "  adding: outputs/checkpoint-500/vocab.json (deflated 75%)\n",
      "  adding: outputs/checkpoint-500/adapter_model.safetensors (deflated 41%)\n",
      "  adding: outputs/checkpoint-500/training_args.bin (deflated 51%)\n",
      "  adding: outputs/checkpoint-500/merges.txt (deflated 77%)\n",
      "  adding: outputs/checkpoint-500/README.md (deflated 66%)\n",
      "  adding: outputs/checkpoint-500/tokenizer.json (deflated 80%)\n",
      "  adding: outputs/checkpoint-500/adapter_config.json (deflated 51%)\n",
      "  adding: outputs/checkpoint-500/tokenizer_config.json (deflated 76%)\n",
      "  adding: outputs/checkpoint-500/scheduler.pt (deflated 55%)\n",
      "  adding: outputs/checkpoint-500/rng_state.pth (deflated 25%)\n",
      "  adding: outputs/checkpoint-500/trainer_state.json (deflated 55%)\n",
      "  adding: outputs/checkpoint-500/special_tokens_map.json (deflated 48%)\n",
      "  adding: outputs/checkpoint-500/added_tokens.json (stored 0%)\n",
      "  adding: outputs/added_tokens.json (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "# zip the file to download it\n",
    "! zip -r outputs.zip outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MqM5bUQkQRh",
    "outputId": "801720bf-ec1b-4316-dc1c-14a8eeeec1f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    " ! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "e_YtCg0lo7RT",
    "outputId": "3a66848b-6a3e-46ec-b85e-157d3f5a74e0"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_ffc11c16-ed18-45da-8b91-c6858669f64b\", \"outputs.zip\", 1920350264)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mount google drive so i can save the file in it\n",
    "from google.colab import files\n",
    "files.download('/content/outputs.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3qGYYxzGmAfa"
   },
   "outputs": [],
   "source": [
    "# send the file to google drive\n",
    "! cp /content/outputs.zip /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2OStVJPpYEX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0eac0f1c9e244728b1822283bed7ffc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f214f2c799f4952a504f60c50dde628": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e8062385c5644fc9e68da9eec64236f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edf043d4dc184c058135f9d5282b09f4",
      "placeholder": "​",
      "style": "IPY_MODEL_78acfd5f456e417da7d45c7c216437a8",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "328613d380ff4b2fb784fd3c52cb4b9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_722f54204229436da43aedac46242610",
      "placeholder": "​",
      "style": "IPY_MODEL_0eac0f1c9e244728b1822283bed7ffc3",
      "value": ""
     }
    },
    "3942ef77622546d98798bde3c9029367": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc31b9ea324a4833aad509f1410f333f",
      "placeholder": "​",
      "style": "IPY_MODEL_91c1e93743ad454eb03687b60b1bd14e",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "5a38e1e245d3409ab2d06b976c0fc954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5dd6cd338c004d349a7ca12621ac845b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2e8062385c5644fc9e68da9eec64236f",
       "IPY_MODEL_328613d380ff4b2fb784fd3c52cb4b9d",
       "IPY_MODEL_a08266752c104fe88c9a51aee2dd0f7e",
       "IPY_MODEL_96e007b463894103a2b392edd15e9152",
       "IPY_MODEL_3942ef77622546d98798bde3c9029367"
      ],
      "layout": "IPY_MODEL_ce4cbe0e35b446e3adafa39fb9165902"
     }
    },
    "5fa1feb5b23f4abea9755ae890af97d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "722f54204229436da43aedac46242610": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78acfd5f456e417da7d45c7c216437a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91c1e93743ad454eb03687b60b1bd14e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96e007b463894103a2b392edd15e9152": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_1f214f2c799f4952a504f60c50dde628",
      "style": "IPY_MODEL_5fa1feb5b23f4abea9755ae890af97d2",
      "tooltip": ""
     }
    },
    "a08266752c104fe88c9a51aee2dd0f7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_c7b6267389d64fa58e91546681cd2426",
      "style": "IPY_MODEL_5a38e1e245d3409ab2d06b976c0fc954",
      "value": true
     }
    },
    "c7b6267389d64fa58e91546681cd2426": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce4cbe0e35b446e3adafa39fb9165902": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "edf043d4dc184c058135f9d5282b09f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc31b9ea324a4833aad509f1410f333f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
